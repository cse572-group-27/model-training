{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import csv\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from nltk.tokenize import TextTilingTokenizer\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from torch import nn\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-qcbkv_sd43",
        "outputId": "4a3a353e-9441-442e-a0b4-6743d3fd5b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbrSvlr1Zl4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6599d557-bceb-4572-c8fb-b88f83505306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CNAp-Xs1N3eIhL96mqNkfaYE413By43q/CSE572_final_project\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/CSE572_final_project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = {}\n",
        "dictionary_reverse = []\n",
        "with open(\"dictionary.txt\", \"r\") as dictionary_file:\n",
        "    for i, line in enumerate(dictionary_file):\n",
        "        dictionary[line.strip()] = i\n",
        "        dictionary_reverse.append(line.strip())"
      ],
      "metadata": {
        "id": "AdXvgT1Oz4nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Code"
      ],
      "metadata": {
        "id": "So1Lh-VksFwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataframeSeriesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x_dataframe, y_series):\n",
        "        '''\n",
        "        Takes a data frame of x values and associated y series\n",
        "        where x_dataframe.iloc[i]'s corresponding y value\n",
        "        is y_series.iloc[i]\n",
        "        '''\n",
        "        self.x_data_frame = x_dataframe\n",
        "        self.y_series = y_series\n",
        "        self.len = len(x_dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return np.array(self.x_data_frame.iloc[index]).astype(np.float32), np.array(self.y_series.iloc[index]).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "def train_model(model,\n",
        "    dataset,\n",
        "    batch_sz=100,\n",
        "    learning_rate=0.1,\n",
        "    loss_fn=nn.BCELoss(),\n",
        "    optimizer_type=\"sgd\",\n",
        "    num_epochs=100):\n",
        "\n",
        "    train_dataloader = DataLoader(dataset=dataset, batch_size=batch_sz, shuffle=True)\n",
        "\n",
        "    if optimizer_type == \"sgd\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_type == \"adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_type == \"rmsprop\":\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    loss_values = []\n",
        "\n",
        "    for _ in range(num_epochs):\n",
        "        for X, y in train_dataloader:\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            pred = model(X).squeeze()\n",
        "            loss = loss_fn(pred, y.squeeze())\n",
        "            loss_values.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return loss_values\n",
        "\n",
        "class TwoHiddenLayerCategorizingNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(TwoHiddenLayerCategorizingNeuralNetwork, self).__init__()\n",
        "        self.hidden_1 = nn.Linear(input_dim, 128)\n",
        "        nn.init.kaiming_uniform_(self.hidden_1.weight, nonlinearity=\"relu\")\n",
        "        self.hidden_2 = nn.Linear(128, 128)\n",
        "        nn.init.kaiming_uniform_(self.hidden_2.weight, nonlinearity=\"relu\")\n",
        "        self.out = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.hidden_1(x))\n",
        "        x = torch.nn.functional.relu(self.hidden_2(x))\n",
        "        x = torch.nn.functional.sigmoid(self.out(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "LSzXRy74Zx1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Code to Run a 5 Fold Experiment"
      ],
      "metadata": {
        "id": "eeIcvryN7lns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(\n",
        "        train_dataframe,\n",
        "        batch_sz=100,\n",
        "        learning_rate=0.1,\n",
        "        loss_fn=nn.BCELoss(),\n",
        "        optimizer_type=\"sgd\",\n",
        "        num_epochs=100):\n",
        "    input_features = len(train_dataframe.columns) - 1\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=400)\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_stds = []\n",
        "    validation_accuracies = []\n",
        "    validation_stds = []\n",
        "\n",
        "    x = train_dataframe[train_dataframe.columns[:-1]]\n",
        "    y_binary = train_dataframe[\"label\"].map(lambda x: 0 if x == \"non-sponsor\" else 1)\n",
        "\n",
        "    for train_index, validation_index in kf.split(x):\n",
        "\n",
        "        train_x = x.iloc[train_index]\n",
        "        validation_x = x.iloc[validation_index]\n",
        "        train_y = y_binary[train_index]\n",
        "        validation_y = y_binary[validation_index]\n",
        "\n",
        "        model = TwoHiddenLayerCategorizingNeuralNetwork(input_features)\n",
        "\n",
        "        train_model(model,\n",
        "                    DataframeSeriesDataset(train_x, train_y),\n",
        "                    batch_sz,\n",
        "                    learning_rate,\n",
        "                    loss_fn,\n",
        "                    optimizer_type,\n",
        "                    num_epochs)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            train_output = model(torch.from_numpy(np.array(train_x).astype(np.float32)))\n",
        "            train_predictions = train_output.numpy() > 0.5\n",
        "            train_correct = np.sum(train_predictions.squeeze() == train_y)\n",
        "\n",
        "            validation_output = model(torch.from_numpy(np.array(validation_x).astype(np.float32)))\n",
        "            validation_predictions = validation_output.numpy() > 0.5\n",
        "            validation_correct = np.sum(validation_predictions.squeeze() == validation_y)\n",
        "\n",
        "        train_accuracies.append(train_correct/len(train_x))\n",
        "        validation_accuracies.append(validation_correct/len(validation_x))\n",
        "\n",
        "    np_train_accuracies = np.array(train_accuracies)\n",
        "    np_validation_accuracies = np.array(validation_accuracies)\n",
        "    return train_accuracies, validation_accuracies, np.average(np_train_accuracies), np.std(np_train_accuracies), np.average(np_validation_accuracies), np.std(np_validation_accuracies)"
      ],
      "metadata": {
        "id": "iieGzBmHr_om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "xL4EO_JT7soP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_optimizer(learning_rates, optimizers, batch_szs, train_dataframe):\n",
        "  best_learning_rate = None\n",
        "  best_optimizer = None\n",
        "  best_batch_sz = None\n",
        "  best_train_accuracy = 0.0\n",
        "  best_train_std = 0.0\n",
        "  best_validation_accuracy = 0.0\n",
        "  best_validation_std = 0.0\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for learning_rate in learning_rates:\n",
        "      for optimizer in optimizers:\n",
        "          print(best_validation_accuracy)\n",
        "          for batch_sz in batch_szs:\n",
        "              print(learning_rate, optimizer, batch_sz)\n",
        "              _, _, average_train_accuracy, std_train_accuracy, average_validation_accuracy, std_validation_accuracy = run_experiment(\n",
        "                  train_dataframe,\n",
        "                  learning_rate=learning_rate,\n",
        "                  optimizer_type=optimizer,\n",
        "                  batch_sz=batch_sz,\n",
        "                  num_epochs=15)\n",
        "              if average_validation_accuracy > best_validation_accuracy:\n",
        "                  best_train_accuracy = average_train_accuracy\n",
        "                  best_train_std = std_train_accuracy\n",
        "                  best_validation_accuracy = average_validation_accuracy\n",
        "                  best_validation_std = std_validation_accuracy\n",
        "                  best_learning_rate = learning_rate\n",
        "                  best_optimizer = optimizer\n",
        "                  best_batch_sz = batch_sz\n",
        "              results.append(((learning_rate, optimizer, batch_sz), average_validation_accuracy, std_validation_accuracy))\n",
        "\n",
        "  print(f\"Best train accuracy: {best_train_accuracy}\")\n",
        "  print(f\"Best train std: {best_train_std}\")\n",
        "  print(f\"Best validation accuracy: {best_validation_accuracy}\")\n",
        "  print(f\"Best validation std: {best_validation_std}\")\n",
        "  print(f\"Best learning rate: {best_learning_rate}\")\n",
        "  print(f\"Best optimizer: {best_optimizer}\")\n",
        "  print(f\"Best batch size: {best_batch_sz}\")\n",
        "  print(results)"
      ],
      "metadata": {
        "id": "iqUwD8PN7sFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training YouTube Model\n"
      ],
      "metadata": {
        "id": "28kw7eaNsBbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "umUyVxDRLvoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "segment_texts = []\n",
        "segment_labels = []\n",
        "\n",
        "with open(\"segments.csv\") as f:\n",
        "  reader = csv.reader(f)\n",
        "  next(reader)\n",
        "  for row in reader:\n",
        "    segment_labels.append(row[2])\n",
        "    segment_texts.append(row[3])\n",
        "\n",
        "vectorizer = CountVectorizer(vocabulary=dictionary.keys())\n",
        "train_matrix = vectorizer.transform(segment_texts).toarray()\n",
        "\n",
        "vectorizer_dataframe = pd.DataFrame(train_matrix, columns=list(map(lambda word: f\"{word}_presence\", dictionary.keys())))\n",
        "vectorizer_dataframe[\"label\"] = segment_labels\n",
        "\n",
        "x_train, x_test, y_train, y_test_actual = train_test_split(train_matrix, segment_labels, train_size=0.8, test_size=0.2, random_state=400)\n",
        "\n",
        "train_dataframe = pd.DataFrame(x_train, columns=list(map(lambda word: f\"{word}_presence\", dictionary.keys())))\n",
        "train_dataframe[\"label\"] = y_train"
      ],
      "metadata": {
        "id": "6mDrBYSfsjRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5-Fold Cross Validation for Optimizing Hyperparameters"
      ],
      "metadata": {
        "id": "N7fOUR4nLW3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning_rates = [0.0001, 0.001, 0.01]\n",
        "# optimizers = [\"adam\", \"rmsprop\"]\n",
        "# batch_szs = [10, 100, 500]\n",
        "\n",
        "learning_rates = [0.0001]\n",
        "optimizers = [\"rmsprop\"]\n",
        "batch_szs = [10]\n",
        "\n",
        "find_best_optimizer(learning_rates, optimizers, batch_szs, train_dataframe)\n",
        "\n"
      ],
      "metadata": {
        "id": "e8H5PGigHd13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9305a753-8024-40cd-94d9-617fa57b2633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0001 rmsprop 10\n",
            "Best train accuracy: 0.9479875252270755\n",
            "Best train std: 0.002524263714953769\n",
            "Best validation accuracy: 0.855721479423511\n",
            "Best validation std: 0.01627572654379301\n",
            "Best learning rate: 0.0001\n",
            "Best optimizer: rmsprop\n",
            "Best batch size: 10\n",
            "[((0.0001, 'rmsprop', 10), 0.855721479423511, 0.01627572654379301)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training with Optimized Hyperparameters"
      ],
      "metadata": {
        "id": "p7hL3ZS4LaT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = len(train_dataframe.columns) - 1\n",
        "\n",
        "yt_model = TwoHiddenLayerCategorizingNeuralNetwork(input_features)\n",
        "\n",
        "x = train_dataframe[train_dataframe.columns[:-1]]\n",
        "y_binary = train_dataframe[\"label\"].map(lambda x: 0 if x == \"non-sponsor\" else 1)\n",
        "\n",
        "train_model(yt_model, DataframeSeriesDataset(x, y_binary), batch_sz=15, optimizer_type=\"rmsprop\", num_epochs=15, learning_rate=0.0001)\n",
        "\n",
        "y_test_predict = yt_model(torch.from_numpy(np.array(x_test).astype(np.float32))).detach().numpy() > 0.5\n",
        "y_test_actual_binary = np.array(list(map(lambda x: 0 if x == \"non-sponsor\" else 1, y_test_actual)))\n",
        "test_correct = np.sum(y_test_predict.squeeze() == np.array(y_test_actual_binary))\n",
        "print(test_correct/len(x_test))"
      ],
      "metadata": {
        "id": "6j0dVEsDFyqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4c4589-090e-4527-c250-a56164844928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8661844484629295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Output"
      ],
      "metadata": {
        "id": "-N4279RaLjXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"example_transcript.txt\") as f:\n",
        "  raw_transcript = f.readline()\n",
        "\n",
        "transcript = raw_transcript.replace(\".\", \".\\n\\n\")\n",
        "\n",
        "segmenter = TextTilingTokenizer(cutoff_policy=0)\n",
        "segments = segmenter.tokenize(transcript)\n",
        "\n",
        "spotify_test_vectorization = vectorizer.transform(segments).toarray()\n",
        "\n",
        "spotify_predicted_labels = yt_model(torch.from_numpy(np.array(spotify_test_vectorization).astype(np.float32)))\n",
        "\n",
        "for segment, label in zip(segments, spotify_predicted_labels):\n",
        "  print(f\"{'Sponsor' if label > 0.5 else 'Non-Sponsor'}: {segment}\")\n"
      ],
      "metadata": {
        "id": "61JcboYgDCUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e026bbf-3d50-4093-d991-e917f1a65f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-Sponsor: Hi, I'm Kenya and I am one year in you're listening to the GC youth Ministries podcast.\n",
            "\n",
            " You plus me plus we welcome welcome pull up a chair grab a seed and listening.\n",
            "Non-Sponsor: \n",
            "\n",
            "  All right, so welcome.\n",
            "\n",
            " I'm Anya.\n",
            "\n",
            " Hi Kenya.\n",
            "\n",
            " Are you feeling tired tired? You don't know dying.\n",
            "\n",
            " Hmm.\n",
            "\n",
            " I can assure you that much.\n",
            "\n",
            " I can only imagine so hello to everyone that's listening in welcome.\n",
            "\n",
            " Hey, how are you sir? How are y'all? How are you doing? Kenya? You asked me how I was doing.\n",
            "\n",
            " Yeah.\n",
            "\n",
            " Look at that politeness.\n",
            "\n",
            "  Not that person.\n",
            "\n",
            " I'm doing good doing better feeling excited.\n",
            "\n",
            " I'm excited about this.\n",
            "Non-Sponsor: \n",
            "\n",
            " Me too.\n",
            "\n",
            " Yeah, because I feel like this is fine like our baby.\n",
            "\n",
            " Hmm.\n",
            "\n",
            " I think Kenny and I have been trying to do a podcast for like a year outside of thousands of years and then and then pasta gay was like go ahead and gave us the green light because that's what it's all about.\n",
            "\n",
            " Right supporting our young people and letting them just like Flex their wings like the wings of they  Spread their wings as a thing he'll but okay.\n",
            "Non-Sponsor: \n",
            "\n",
            " Alright.\n",
            "\n",
            " So in this podcast we want to just have an open conversation.\n",
            "\n",
            " I think that one of the main things we were focusing on was the importance of having a three-way conversation with the you being not you mañana not you whoever is listening, but you God and we want to make sure that we are not just asking ourselves why God isn't like talking to us, but also making sure that we are seeking his voice each and every day.\n",
            "\n",
            "  There's also the me part of the equation whose that me is me me me me gummy is yummy as me? No actually, it's me that he liked me better already.\n",
            "\n",
            " So the me is us is who me when Nia me Kenya me Paul wherever you are the Jill Hey Joe, how you doing? What's up? So me is who the perp wherever the person is.\n",
            "Non-Sponsor: \n",
            "\n",
            "  The individual who's living life going through life understanding life struggling with life.\n",
            "\n",
            " Hmm because overall goals its adult life in jail life is hard and then we have we who's we what so we well we this is the third part of our equation the third part of our conversation is what is the church the we is the church or we as a people, who are we as Seventh-Day Adventists? Who are we as the young people of this generation?  And of the church and we want to make sure that we remember that we are a community we need to act like one and we need to move like one and we need to worry for each other like a community does worry for each other.\n",
            "Non-Sponsor: \n",
            "\n",
            " So I think that that's an important piece of our conversation because as a community just because we're moving together in one sentiment does not mean that we're always going to see eye-to-eye that were not that were always going to agree because we come from different backgrounds and experience different things but the importance of having a conversation like this.\n",
            "\n",
            "  This is that as a community we can come and we can be kind to each other and listen to each other stories and opinions true dat.\n",
            "Non-Sponsor: \n",
            "\n",
            " Hmm.\n",
            "\n",
            " I like so Kenya.\n",
            "\n",
            " What does God I mean to you who is God was Jesus? Who is the Holy Spirit? Yeah.\n",
            "\n",
            " Are they? Who is them singular? Well, the Bible goes on and on about who they are.\n",
            "\n",
            " Right God is the beginning in the end.\n",
            "\n",
            " He is the Alpha and the Omega he is the all-mighty the all-knowing he is omnipotent omnipresent.\n",
            "\n",
            "  Isn't all nations.\n",
            "\n",
            " Oh, yeah, they words all of the Omni.\n",
            "\n",
            " All of them.\n",
            "\n",
            " He is the creator he is life.\n",
            "\n",
            " Um, he is the the way right? I'll truth and the light.\n",
            "Non-Sponsor: \n",
            "\n",
            " Yes, and he is I for like my life, I knew that and he is our creator and our heavenly father but going on to a more personal level.\n",
            "\n",
            " I'm a person with just a lot going on all the time a lot.\n",
            "\n",
            "  Hang on outwardly a lot going on inwardly.\n",
            "Non-Sponsor: \n",
            "\n",
            " There's just so much in my head so much in my heart and I've gone through so many things experience so many sometimes very chaotic moments in my life and through it.\n",
            "\n",
            " All.\n",
            "\n",
            " God has been my peace.\n",
            "\n",
            " God has been the one thing that just kind of like grabbed me by the shoulders and it's like all right.\n",
            "\n",
            " It's time to just chill.\n",
            "\n",
            " Yeah, no stop it.\n",
            "\n",
            " Calm down.\n",
            "\n",
            " Looks like we need a moment stand still and I mean in the Bible, there's Psalms 46:10.\n",
            "Non-Sponsor: \n",
            "\n",
            "  It says be still and know that I am God and I think that's one of my favorite affirmations where God is like just stand there and watch me work my wonders watch me be God watch me be able to work my wonders in your life and just show you of everything.\n",
            "\n",
            " You know, I'm capable of and I think that God for me has definitely been that still Small Voice that still whisper that we know from First Kings where it's like he didn't come in the fire.\n",
            "\n",
            " He didn't come in the strong wind.\n",
            "\n",
            " He came in the small whisper and to me he's constantly  My small was burned I depend on him for all my piece all your calmness all of them.\n",
            "Sponsor: \n",
            "\n",
            " All the comments made need.\n",
            "\n",
            " So I'm just thinking God.\n",
            "\n",
            " This is our mom someone.\n",
            "\n",
            " Yeah, who is God to you and yours? Jesús Cristo El espíritu Santo karate.\n",
            "\n",
            "  Letsa, yes, I didn't M1 is pretty good Multicultural multilingual dealing with everything multicolored all of the things.\n",
            "\n",
            "  So I said God loves me.\n",
            "\n",
            " I know because I was the first that could come into my head about God and but pray for me my mom.\n",
            "Non-Sponsor: \n",
            "\n",
            " So who is God to me God to me out of everything that we can think of when we think about God the word that comes to me is provider God is the person I look for when I am in need of things and in need of something and not  Always necessarily as in God, I need money God.\n",
            "\n",
            " I need a new iPhone because my speaker is messed up.\n",
            "\n",
            " Oh God, I need furniture for my apartment because it has none but outside of those things.\n",
            "\n",
            " I think to look to God for when I'm in I'm lacking Joy.\n",
            "\n",
            " I need to join God fills me in that way and God when I am like whatever I'm lacking in God is always there and  that brought me can you actually reminded me of Psalms 23 where it says the Lord is my shepherd.\n",
            "Sponsor: \n",
            "\n",
            " I shall not want and it's not the want of a child where it's like Mommy I need I want this and I want a new bar because Barbies are cute and I like pink but it's the the living without we actually look this up and in the Hebrew, it's not lacking not not in need of anything else your your fulfilled to the most.\n",
            "\n",
            "  You could be and there's nothing else that you seek because God is there and God has filled everything that you could think of he provided the money, but he also provided the joy and the love that you're seeking and he fills all of that.\n",
            "\n",
            " So that's who God is to me that reminds me of my favorite biblical verse when you said like we're not lacking of like have enough of something is in 2nd Corinthians 9 12.\n",
            "\n",
            " I'm not mistaken Second Corinthians says his grace is  sufficient for me is enough.\n",
            "\n",
            " Yeah, it's more everything.\n",
            "Non-Sponsor: \n",
            "\n",
            " It's literally all-encompassing.\n",
            "\n",
            " I do not lack of anything and I think that it's a great point that you bring up that in Psalms 23.\n",
            "\n",
            " It's literally talking about like there is nothing else.\n",
            "\n",
            " I could ever want nothing you give you all your for your head.\n",
            "\n",
            "  Green Pastures shiny so I don't want to thank you, but thanks God for the intention.\n",
            "\n",
            " Okay.\n",
            "\n",
            " So now there's a second part of our mission as we just covered the you part which is God and we wanted to have a moment to just be able to say, you know, who's got to me, but I think it's a  Nice moment for you today at some point if you have an opportunity, I don't mean one.\n",
            "Non-Sponsor: \n",
            "\n",
            " Yeah, I mean you listening you have an opportunity today to just do these things.\n",
            "\n",
            " Yeah, sit down and think about who is God to you.\n",
            "\n",
            " You can even pause this right now and just go ahead and stop it.\n",
            "\n",
            " Stop a moment and just be like who is God to me and meditate on all the Wonders and all the greatness of God, but there is a second part.\n",
            "Sponsor: \n",
            "\n",
            " Well that hmm, and it's the Meat part.\n",
            "\n",
            " So who Am she who is me? Who is me is when y'all who is Manya?  Nia nia, nia is Zambian by birth? Yes American by living.\n",
            "\n",
            " Hmm and Queens from Queens.\n",
            "\n",
            " The Boogie know why is a daughter.\n",
            "\n",
            " When is the sister? When is nice when use crazy when it's loud? When is messy when your stock itive fun? When is a good sister? She's really good.\n",
            "Sponsor: \n",
            "\n",
            " My sister's think so when he was also a good friend, my friend.\n",
            "\n",
            "  Ends tell me that Allah will check I'm gonna make some calls.\n",
            "\n",
            " My friends are always like when you're the best.\n",
            "\n",
            " Oh, he's a good friend.\n",
            "\n",
            " That's my idea is amazing when you has a song Wait what dead so I used to I used to take care of this kid, and she made me a song and it's when he's amazing when he has amazing.\n",
            "Sponsor: \n",
            "\n",
            " It's amazing when you when you yeah, and with that we're out guys filled with - amazingness.\n",
            "\n",
            "  So who is Kenya? Who is she who is Kenya? Well, Kenya is many things.\n",
            "\n",
            " I think ever revolutionising ever evolving, you know, a major definitely an English.\n",
            "\n",
            " I'm just an English everything here.\n",
            "\n",
            " But no Kenya is regular girl from the Bronx and you know born and raised born to Guatemalan mother during father raised by a wonderful stepfather.\n",
            "Sponsor: \n",
            "\n",
            " Who is Dominican surrounded by  A lot of love big sister which comes with a lot of responsibilities but also with such beautiful memories Kenya is not a wife.\n",
            "\n",
            " She's not a wife.\n",
            "\n",
            " That's a new title.\n",
            "\n",
            " Yes husband and I love is life.\n",
            "\n",
            " Shout out to her husband.\n",
            "\n",
            " And yes Kenya.\n",
            "\n",
            " I definitely love to live by what the Pathfinder lock talks about and it's you know, I'm friend.\n",
            "Sponsor: \n",
            "\n",
            "  I'll find out I'm a servant of God and a friend to man and I strive to be that I might not be that all the time, but I definitely strive to be God's Urban and everything I do and try to be a friend to everyone.\n",
            "\n",
            " Yeah, I think that's what were called to do.\n",
            "\n",
            " And I think Kenya's just someone who is passionate about life excited about life excited to learn and read and then someday hopefully right it when I read a book and stuff.\n",
            "\n",
            " Oh, you ready? Y'all remember the  This and the year 2040 call me on if I haven't read the book.\n",
            "\n",
            " It's written by Kenya vs.\n",
            "Sponsor: \n",
            "\n",
            " Lily on a memoir.\n",
            "\n",
            "  what happened during the GC podcast the a look behind so the next part is we it was we who is our the we of this equation will them well, like we mentioned before you know, this we want to make sure we include the community which is our church the we part of this is our our church as a whole and we want to make sure that in the conversations that we have here, which we will have many and they will be very interesting we will  Get to hear from some great people who we have invited as guests on the show.\n",
            "Non-Sponsor: \n",
            "\n",
            " And I think that they will give us an understanding of how different we are as a people but how much we can learn from one another so we always have to remember that although it gets tough.\n",
            "Sponsor: \n",
            "\n",
            " Sometimes being you know, young person Adventists who ever we have a community that we can always reach out to and hopefully that Community will always be able to take you in with open arms, you know, remembering what  is the church what as Adventists do we believe in what we believe in as a people of the Bible.\n",
            "\n",
            " I love the word of God.\n",
            "\n",
            " You know, what do we believe in? Who are we now what is our identity as the people who are waiting for his second coming.\n",
            "Sponsor: \n",
            "\n",
            " So I think that's something that we will be able to just learn more about and hopefully we'll keep the conversation always remembering that there is a community out there with its own opinions and thoughts and love to hear about it.\n",
            "\n",
            " Yes.\n",
            "\n",
            "  I'm excited about uncovering will the church is or what the church the things that we think about and what the church stances are on those things and points of discussion and how does being part of the church being Seventh-day Adventist affect us and our daily lives.\n",
            "\n",
            " Hmm.\n",
            "\n",
            " Yeah.\n",
            "\n",
            " Yes.\n",
            "\n",
            " I did.\n",
            "\n",
            " I'm excited for all the conversations that I know we're going to have this room and for all of the people who are in good engage with us, hopefully and for all of the amazing guests that we have.\n",
            "Sponsor: \n",
            "\n",
            "  Signed up as the conversations and the stories that we will hear and hopefully you guys will also be excited.\n",
            "\n",
            " So in order to make sure you are W excited when yeah, when does it all when does it all begin? It begins? We are will be inversely or headphones.\n",
            "\n",
            " Okay.\n",
            "\n",
            " This is a teaser guy.\n",
            "\n",
            " Sorry.\n",
            "\n",
            " Oh, it's like a whole episode but it's not as it should be um, but we'll be in your headphones in your car.\n",
            "\n",
            "  Stereos and your house is on a February the 17th of 2020.\n",
            "\n",
            " I have one we have a classically I don't know no.\n",
            "Non-Sponsor: \n",
            "\n",
            "  No, it's not it.\n",
            "\n",
            "  February 17 guys, we ready we're so wack.\n",
            "\n",
            " Um, but if after listening to all of that and you're like crazy young adults kind of makes sense and I kind of like them and I kind of want to join this conversation and be part of the part of the church be part of the we'd be part of the speed out of this community.\n",
            "\n",
            " How does one become  Part of that Kenya.\n",
            "\n",
            " How does one join the conversation shared their thoughts explain how when he was better than Kenya.\n",
            "Non-Sponsor: \n",
            "\n",
            " How do they go ahead and do that? Well, all of that - the last part first of all, if you're not already following us on our social media Pages do so right.\n",
            "\n",
            " Now you can find us on Instagram as g c by T H Min which stands for GC youth Ministries all like, you know abbreviated.\n",
            "Non-Sponsor: \n",
            "\n",
            " We you can also find this is GC youth  trees on Facebook.\n",
            "\n",
            " So make sure you follow us there you friend us there you add us there and we will be using our hashtag our official hashtag is going to be hashtag gcy podcast GC youth podcast.\n",
            "\n",
            " And if you want to give your opinion on a topic, we will definitely be present on the social media and also you can social media the social medias and also you can upload a picture of video anything you'd like and use that as a hashtag if  Something you want to share with us and we'll definitely check it out and make mention on the next episode.\n",
            "\n",
            " We're looking forward to hearing from you guys and learning more about how us going through this Learning Journey with podcasting and understanding more about the church and who we are and who God is that we want to see your feedback and how far you're moving in this journey as well too.\n",
            "Non-Sponsor: \n",
            "\n",
            " So right now we're excited because we're going to unveil one of our segments that we're super excited.\n",
            "\n",
            "  Excited about and being that I'm in the presence of an amazing pastor's wife.\n",
            "\n",
            " Yes.\n",
            "\n",
            " He has many much wisdom much many a lot.\n",
            "\n",
            " She has a lot of wisdom to share with us, you know.\n",
            "\n",
            " So one of the segments that we have is a pin it thought pin it we're going to pin something on to our Board of life.\n",
            "Non-Sponsor: \n",
            "\n",
            " I know memories if you think about Pinterest and that analogy you kind of see where that train of thought is going but it's  Actually something that you can keep with you throughout the week throughout your month as you reflect back on this podcast.\n",
            "\n",
            " So Kenya.\n",
            "\n",
            " Hmm.\n",
            "\n",
            " What is are pinnate thought for this teaser for this for life for this month? Well are pinnate thought for today is remember to drink water.\n",
            "\n",
            " Remember to drink your water I suck at drinking water and when you were so gracious and brought me a little bit of water if you had a video.\n",
            "\n",
            " Yeah, it would see that she brought me a little bit.\n",
            "\n",
            "  Of water definitely need to stay hydrated.\n",
            "Sponsor: \n",
            "\n",
            " It's good for you.\n",
            "\n",
            " It's good for your body and it just makes you glow from the inside out.\n",
            "\n",
            " But also remember to always come back to the Fountain of Life.\n",
            "\n",
            " Remember to always come back and drink from that living water and come back to that.\n",
            "\n",
            " Well, and that living water will make sure that you thirst no more so drink your water not just your physical water, but also your spiritual water Bibles book girls.\n",
            "Non-Sponsor: \n",
            "\n",
            " Yes.\n",
            "\n",
            " Yes.\n",
            "\n",
            " Remember it.\n",
            "\n",
            " That's what your what your homework is.\n",
            "\n",
            "  For the rest of this month awesome.\n",
            "\n",
            " I'm excited.\n",
            "\n",
            " So till next time till we meet again.\n",
            "\n",
            " So basically we're leaving.\n",
            "\n",
            " Um, so that's the end shout out to Sophie and Esau for their birthdays Kampai.\n",
            "\n",
            "  For the rest of this month awesome.\n",
            "\n",
            " I'm excited.\n",
            "\n",
            " So till next time till we meet again.\n",
            "\n",
            " So basically we're leaving.\n",
            "Sponsor: \n",
            "\n",
            " Um, so that's the end shout out to Sophie and Esau for their birthdays Kampai.\n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Podcast Model"
      ],
      "metadata": {
        "id": "kIUglnraLlRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "Mx-55igu583C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "podcast_segment_texts = []\n",
        "podcast_segment_labels = []\n",
        "\n",
        "with open(\"spotify-train.csv\") as f:\n",
        "  reader = csv.reader(f)\n",
        "  next(reader)\n",
        "  for row in reader:\n",
        "    podcast_segment_labels.append(row[1])\n",
        "    podcast_segment_texts.append(row[0])\n",
        "\n",
        "vectorizer = CountVectorizer(vocabulary=dictionary.keys())\n",
        "podcast_train_matrix = vectorizer.transform(podcast_segment_texts).toarray()\n",
        "\n",
        "vectorizer_dataframe = pd.DataFrame(podcast_train_matrix, columns=list(map(lambda word: f\"{word}_presence\", dictionary.keys())))\n",
        "vectorizer_dataframe[\"label\"] = podcast_segment_labels\n",
        "\n",
        "x_podcast_train, x_podcast_test, y_podcast_train, y_podcast_test_actual = train_test_split(podcast_train_matrix, podcast_segment_labels, train_size=0.8, test_size=0.2, random_state=400)"
      ],
      "metadata": {
        "id": "riDUFYOr5h7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upsampling Ads\n",
        "\n",
        "There are fewer ads than non ads so we oversample to remedy this."
      ],
      "metadata": {
        "id": "qYjarH4f555t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=400)\n",
        "\n",
        "x_podcast_train_oversample, y_podcast_train_oversample = ros.fit_resample(x_podcast_train, y_podcast_train)\n",
        "\n",
        "podcast_train_dataframe_oversampled = pd.DataFrame(x_podcast_train_oversample, columns=list(map(lambda word: f\"{word}_presence\", dictionary.keys())))\n",
        "podcast_train_dataframe_oversampled[\"label\"] = y_podcast_train_oversample\n",
        "\n",
        "print(f\"Num sponsored samples: {podcast_train_dataframe_oversampled[podcast_train_dataframe_oversampled.label=='sponsor'].shape[0]}\")\n",
        "print(f\"Num non sponsored samples: {podcast_train_dataframe_oversampled[podcast_train_dataframe_oversampled.label=='non-sponsor'].shape[0]}\")"
      ],
      "metadata": {
        "id": "ghQYgETJ54rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458f8ad8-acc3-408a-a2dd-54acca15efb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num sponsored samples: 332\n",
            "Num non sponsored samples: 332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5-Fold Cross Validation for Optimizing Hyperparameters"
      ],
      "metadata": {
        "id": "DxbCHwYH753R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.0001, 0.001, 0.01]\n",
        "optimizers = [\"adam\", \"rmsprop\"]\n",
        "batch_szs = [10, 100, 500]\n",
        "\n",
        "find_best_optimizer(learning_rates, optimizers, batch_szs, podcast_train_dataframe_oversampled)\n",
        "\n"
      ],
      "metadata": {
        "id": "COG6kc3x74Pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ce7480-55af-4d10-cc9e-c94b7d13f57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0001 adam 10\n",
            "0.0001 adam 100\n",
            "0.0001 adam 500\n",
            "0.9909774436090226\n",
            "0.0001 rmsprop 10\n",
            "0.0001 rmsprop 100\n",
            "0.0001 rmsprop 500\n",
            "0.9909774436090226\n",
            "0.001 adam 10\n",
            "0.001 adam 100\n",
            "0.001 adam 500\n",
            "0.9909774436090226\n",
            "0.001 rmsprop 10\n",
            "0.001 rmsprop 100\n",
            "0.001 rmsprop 500\n",
            "0.9909774436090226\n",
            "0.01 adam 10\n",
            "0.01 adam 100\n",
            "0.01 adam 500\n",
            "0.9909774436090226\n",
            "0.01 rmsprop 10\n",
            "0.01 rmsprop 100\n",
            "0.01 rmsprop 500\n",
            "Best train accuracy: 0.9951049941237274\n",
            "Best train std: 0.002260596653276766\n",
            "Best validation accuracy: 0.9909774436090226\n",
            "Best validation std: 0.011050329666691056\n",
            "Best learning rate: 0.0001\n",
            "Best optimizer: adam\n",
            "Best batch size: 10\n",
            "[((0.0001, 'adam', 10), 0.9909774436090226, 0.011050329666691056), ((0.0001, 'adam', 100), 0.9082365003417635, 0.05885659646483553), ((0.0001, 'adam', 500), 0.7816700843016633, 0.10561239298221829), ((0.0001, 'rmsprop', 10), 0.9909774436090226, 0.008768348714053098), ((0.0001, 'rmsprop', 100), 0.9352927773980404, 0.03206252490538751), ((0.0001, 'rmsprop', 500), 0.9231601731601732, 0.01999470633878093), ((0.001, 'adam', 10), 0.9879471405787197, 0.003702280172604136), ((0.001, 'adam', 100), 0.9894736842105264, 0.007667698516680888), ((0.001, 'adam', 500), 0.9563454089769878, 0.02786861020553428), ((0.001, 'rmsprop', 10), 0.983447254499886, 0.005608300962977921), ((0.001, 'rmsprop', 100), 0.9864547732968786, 0.008760559929171798), ((0.001, 'rmsprop', 500), 0.9894736842105264, 0.007667698516680888), ((0.01, 'adam', 10), 0.9879585326953748, 0.0036695349947571424), ((0.01, 'adam', 100), 0.9894736842105264, 0.0060150375939849576), ((0.01, 'adam', 500), 0.9894736842105264, 0.007667698516680888), ((0.01, 'rmsprop', 10), 0.989462292093871, 0.0036742004684999882), ((0.01, 'rmsprop', 100), 0.9909774436090226, 0.005626552461314191), ((0.01, 'rmsprop', 500), 0.9894736842105264, 0.007667698516680888)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [((0.0001, 'adam', 10), 0.9909774436090226, 0.011050329666691056), ((0.0001, 'adam', 100), 0.9082365003417635, 0.05885659646483553), ((0.0001, 'adam', 500), 0.7816700843016633, 0.10561239298221829), ((0.0001, 'rmsprop', 10), 0.9909774436090226, 0.008768348714053098), ((0.0001, 'rmsprop', 100), 0.9352927773980404, 0.03206252490538751), ((0.0001, 'rmsprop', 500), 0.9231601731601732, 0.01999470633878093), ((0.001, 'adam', 10), 0.9879471405787197, 0.003702280172604136), ((0.001, 'adam', 100), 0.9894736842105264, 0.007667698516680888), ((0.001, 'adam', 500), 0.9563454089769878, 0.02786861020553428), ((0.001, 'rmsprop', 10), 0.983447254499886, 0.005608300962977921), ((0.001, 'rmsprop', 100), 0.9864547732968786, 0.008760559929171798), ((0.001, 'rmsprop', 500), 0.9894736842105264, 0.007667698516680888), ((0.01, 'adam', 10), 0.9879585326953748, 0.0036695349947571424), ((0.01, 'adam', 100), 0.9894736842105264, 0.0060150375939849576), ((0.01, 'adam', 500), 0.9894736842105264, 0.007667698516680888), ((0.01, 'rmsprop', 10), 0.989462292093871, 0.0036742004684999882), ((0.01, 'rmsprop', 100), 0.9909774436090226, 0.005626552461314191), ((0.01, 'rmsprop', 500), 0.9894736842105264, 0.007667698516680888)]\n",
        "\n",
        "with open(\"nncvoptimization.csv\", \"w+\") as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow([\"lr\", \"optimizer\", \"batchsz\", \"avg_accuracy\", \"std_accuracy\"])\n",
        "  for config, avg_accuracy, std_accuracy in result:\n",
        "    lr, optimizer, batch_sz = config\n",
        "    writer.writerow([lr, optimizer, batch_sz, avg_accuracy, std_accuracy])"
      ],
      "metadata": {
        "id": "llrPCvT9W3Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training with Optimized Hyperparameters"
      ],
      "metadata": {
        "id": "9iIHHG8-8DuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_features = len(podcast_train_dataframe_oversampled.columns) - 1\n",
        "\n",
        "podcast_model = TwoHiddenLayerCategorizingNeuralNetwork(input_features)\n",
        "\n",
        "x = podcast_train_dataframe_oversampled[podcast_train_dataframe_oversampled.columns[:-1]]\n",
        "y_binary = podcast_train_dataframe_oversampled[\"label\"].map(lambda x: 0 if x == \"non-sponsor\" else 1)\n",
        "\n",
        "train_model(podcast_model, DataframeSeriesDataset(x, y_binary), batch_sz=15, optimizer_type=\"rmsprop\", num_epochs=15, learning_rate=0.0001)\n",
        "\n",
        "y_podcast_test_predict = podcast_model(torch.from_numpy(np.array(x_podcast_test).astype(np.float32))).detach().numpy() > 0.5\n",
        "y_podcast_test_actual_binary = np.array(list(map(lambda x: 0 if x == \"non-sponsor\" else 1, y_podcast_test_actual)))\n",
        "y_podcast_test_actual_binary_array = np.array(y_podcast_test_actual_binary)\n",
        "test_correct = np.sum(y_podcast_test_predict.squeeze() == y_podcast_test_actual_binary_array)\n",
        "original_sponsors = y_podcast_test_actual_binary_array == 1\n",
        "new_sponsors = y_podcast_test_predict.squeeze() == 1\n",
        "recall = np.sum(y_podcast_test_predict.squeeze()[original_sponsors] == y_podcast_test_actual_binary_array[original_sponsors])\n",
        "precision = np.sum(y_podcast_test_predict.squeeze()[new_sponsors] == y_podcast_test_actual_binary_array[new_sponsors])\n",
        "\n",
        "print(f\"Overall correct: {test_correct/len(x_podcast_test)}\")\n",
        "print(f\"Recall: {recall/np.sum(original_sponsors)}\")\n",
        "print(f\"Precision: {precision/np.sum(new_sponsors)}\")"
      ],
      "metadata": {
        "id": "b1iTUO2I8A4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7e230e-c228-4308-9342-6f45917a6bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall correct: 0.9775280898876404\n",
            "Recall: 0.875\n",
            "Precision: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Comparison with Original Model"
      ],
      "metadata": {
        "id": "6-GbH19r8JXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_podcast_test_predict = yt_model(torch.from_numpy(np.array(x_podcast_test).astype(np.float32))).detach().numpy() > 0.5\n",
        "y_podcast_test_actual_binary = np.array(list(map(lambda x: 0 if x == \"non-sponsor\" else 1, y_podcast_test_actual)))\n",
        "y_podcast_test_actual_binary_array = np.array(y_podcast_test_actual_binary)\n",
        "test_correct = np.sum(y_podcast_test_predict.squeeze() == y_podcast_test_actual_binary_array)\n",
        "original_sponsors = y_podcast_test_actual_binary_array == 1\n",
        "new_sponsors = y_podcast_test_predict.squeeze() == 1\n",
        "recall = np.sum(y_podcast_test_predict.squeeze()[original_sponsors] == y_podcast_test_actual_binary_array[original_sponsors])\n",
        "precision = np.sum(y_podcast_test_predict.squeeze()[new_sponsors] == y_podcast_test_actual_binary_array[new_sponsors])\n",
        "\n",
        "print(f\"Overall correct: {test_correct/len(x_podcast_test)}\")\n",
        "print(f\"Recall: {recall/np.sum(original_sponsors)}\")\n",
        "print(f\"Precision: {precision/np.sum(new_sponsors)}\")"
      ],
      "metadata": {
        "id": "iEV7jbCu9Il8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ac9de8-65c4-4387-be94-e241379dc106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall correct: 0.6179775280898876\n",
            "Recall: 1.0\n",
            "Precision: 0.19047619047619047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End to End Labeling of Unseen Podcasts"
      ],
      "metadata": {
        "id": "Jd1c4OIHP3WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_files = os.listdir(\"test_transcripts\")\n",
        "\n",
        "for transcript_file in transcript_files:\n",
        "  with open(\"test_transcripts/\" + transcript_file) as f:\n",
        "    raw_transcript = f.readline()\n",
        "\n",
        "  transcript = raw_transcript.replace(\".\", \".\\n\\n\")\n",
        "\n",
        "  segmenter = TextTilingTokenizer(cutoff_policy=0)\n",
        "  segments = segmenter.tokenize(transcript)\n",
        "\n",
        "  spotify_test_vectorization = vectorizer.transform(segments).toarray()\n",
        "\n",
        "  spotify_predicted_labels = podcast_model(torch.from_numpy(np.array(spotify_test_vectorization).astype(np.float32)))\n",
        "\n",
        "  with open(\"test_segmentations_nn/\" + transcript_file.replace(\".txt\", \".csv\"), \"w+\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['label', 'text'])\n",
        "    for segment, label in zip(segments, spotify_predicted_labels):\n",
        "      writer.writerow(['sponsor' if label > 0.5 else 'non-sponsor', segment])\n"
      ],
      "metadata": {
        "id": "aH2V2V6CQAKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}